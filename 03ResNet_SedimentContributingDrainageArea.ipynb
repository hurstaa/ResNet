{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00da325",
   "metadata": {},
   "source": [
    "This notebook calculates the sediment contributing drainage area in the year 2025 for all of ResNet using the methods of Minear and Kondolf (xxxx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "367ecd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1eeb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "# ResNet File location and name\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "resnet_orig = pd.read_csv(f'Outputs/ResNet_{today}.csv') #if running same date\n",
    "# resnet_orig = pd.read_csv(f'Outputs/ResNet_20250601.csv') #if want to input manual date\n",
    "\n",
    "#load canadian dams for calculating\n",
    "canada = pd.read_csv('Inputs/InputCanada.csv')\n",
    "\n",
    "#output file location\n",
    "out_folder = 'Outputs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f5ecf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversions\n",
    "convert1 = 1233.482 #converts m3 to ac-ft is convert1*AF=m3, or from m3 is m3/convert1=AF\n",
    "convert2 = 2.59 #converts km2 and mi2 is convert2*mi2=km2 or from km2 is km2/convert2=mi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "30b9c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine Canada and resnet\n",
    "resnet = pd.concat([resnet_orig,canada],ignore_index=True)\n",
    "\n",
    "resnet = resnet.sort_values(by='ShortID',ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a291a57b-b927-4c6d-bce1-b73acdd83019",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet['yrr'] = resnet['yrr'].replace(0,np.nan) #replace yrr with nan for canadian dams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50866ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually add major Canadian dams to the routing in the Columbia River basin for calculating sediment contributing drainage area\n",
    "\n",
    "## Boundary Dam\n",
    "resnet.loc[resnet.ShortID==117361, 'ToDam'] = 500005 #route to a Canadian dam, not directly to Grand Coulee\n",
    "resnet.loc[resnet.ShortID==117361, 'GRanDTag'] = 500005\n",
    "\n",
    "## Libby Dam\n",
    "resnet.loc[resnet.ShortID==78196, 'ToDam'] = 500003 #route to a Canadian dam, not directly to Grand Coulee\n",
    "resnet.loc[resnet.ShortID==78196, 'GRanDTag'] = 500003\n",
    "\n",
    "## Grand Coulee Dam\n",
    "resnet.loc[resnet.ShortID==117548, 'FromDam'] = resnet.loc[resnet.ShortID==117548, 'FromDam'].apply(\n",
    "lambda x: [num for num in x if num not in {117361,78196}]) #remove Libby and Boundary ShortIDs from Coulee FromDam\n",
    "\n",
    "resnet.loc[resnet.ShortID==117548, 'FromDam'] = resnet.loc[resnet.ShortID==117548, 'FromDam'].apply(\n",
    "lambda x: x + [500002, 500004, 500006]) #Add Canadian dams to Coulee FromDam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6b2074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rivers from ToDam so only dams are routed to dams.\n",
    "\n",
    "damstoriver = resnet.loc[resnet.ToDam<0]\n",
    "\n",
    "while len(damstoriver)>0:\n",
    "    for i in range(len(damstoriver)):\n",
    "        #find a dam that goes to a river instead of another dam\n",
    "        damlocationtofix = damstoriver.index[i] #index of the dam to fix\n",
    "        river = resnet.loc[damlocationtofix,'ToDam'] #ShortID of the river it goes to\n",
    "        riverloc = resnet.loc[resnet.ShortID==river].index #location of the river\n",
    "        rivertodam = resnet.loc[riverloc,'ToDam'] #the ToDam of the river\n",
    "        resnet.loc[damlocationtofix,'ToDam'] = rivertodam.iloc[0] #replace ToDam of target dam with ToDam of river\n",
    "    damstoriver = resnet.loc[resnet.ToDam<0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7515a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now that to dam has been replaced on real dams, remove to dam from rivers\n",
    "resnet.loc[resnet.IsRiverMth==1,'ToDam'] = np.nan\n",
    "\n",
    "#fix terminal dam flag after removing rivers\n",
    "resnet.loc[resnet.ToDam.isna(),'flagTerm'] = 1\n",
    "resnet.loc[resnet.IsRiverMth==1, 'flagTerm'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89fe6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking dams and assigning dam order (similar to stream order). This does not include Rivers.\n",
    "\n",
    "Rank = np.full(len(resnet['ShortID']),np.nan)\n",
    "Rank[np.where(resnet.flagHW==1)[0]] = 1\n",
    "Rank[np.where(resnet.IsRiverMth == 1)[0]] = 0\n",
    "\n",
    "Dam1 = []\n",
    "Dam2 = []\n",
    "DA1 = []\n",
    "DA2 = []\n",
    "\n",
    "DAerrorNumber = 0;\n",
    "i = 1\n",
    "ranknum= np.where(Rank == i)[0]\n",
    "while len(ranknum)>0:\n",
    "    for j in range(len(ranknum)):\n",
    "        thisdam = ranknum[j]\n",
    "\n",
    "        #process nonterminal dams\n",
    "        if resnet.iloc[thisdam].flagTerm == 0: #if the dam is not a terminal dam\n",
    "            thisdamDA = resnet.iloc[thisdam].DivDASqKM #identify the drainage area of dam j\n",
    "            thatdam = np.where(resnet.ShortID == resnet.iloc[thisdam].ToDam)[0][0] #find the downstream dam\n",
    "            thatdamDA = resnet.iloc[thatdam].DivDASqKM #get the drainage area of the downstream dam\n",
    "\n",
    "            #make sure the downstream DA doesn't exceed the upstream DA\n",
    "            if (thatdamDA<thisdamDA):\n",
    "                DAerrorNumber = DAerrorNumber+1\n",
    "                \n",
    "            else:\n",
    "                Rank[thatdam] = Rank[thisdam]+1\n",
    "    i = i+1\n",
    "    ranknum = np.where(Rank == i)[0]\n",
    "\n",
    "if DAerrorNumber != 0:\n",
    "    print(\"Drainage area error: manually investigate drainage areas in GIS\")\n",
    "\n",
    "resnet['Rank']=Rank\n",
    "\n",
    "DAerrors = pd.DataFrame({'Dam1': Dam1, 'Dam2': Dam2, 'DA1': DA1, 'DA2': DA2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65e3472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of rivers\n",
    "resnet = resnet.loc[resnet['IsRiverMth'] != 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "709742c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For unreasonable or nonexistent yrc, replace with the 90th percentile of when dams were built; earlier than 1700 or later than 2024\n",
    "\n",
    "# Identify valid values (1700 ≤ yrc ≤ 2024)\n",
    "valid_yrc = resnet.loc[(resnet['yrc'] >= 1700) & (resnet['yrc'] <= 2024), 'yrc']\n",
    "\n",
    "# Compute the 90th percentile from valid values\n",
    "percentile_90 = np.percentile(valid_yrc, 90)\n",
    "\n",
    "# Replace out-of-range values with the 90th percentile\n",
    "resnet.loc[(resnet['yrc'] < 1700) | (resnet['yrc'] > 2024), \"yrc\"] = percentile_90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b865e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the timeseries\n",
    "t = np.arange(1699, 2051) #run from 1699 to 2050\n",
    "numdam=len(resnet.ShortID); #number of dams\n",
    "numt=len(t); #length of time\n",
    "\n",
    "#create empty variables\n",
    "capcalc = np.full((len(resnet.ShortID), numt), np.nan) #this is a variable that would need to be stored in the structure\n",
    "sedshed = np.full((len(resnet.ShortID), numt), np.nan) #this is the km2 area of the watershed that has sediment getting trapped in reservoir (so contribut DA * trap efficiency)\n",
    "calctrap = np.full((len(resnet.ShortID),numt),0.0)\n",
    "wsedshed = np.full((len(resnet.ShortID), 1), np.nan) #effective sediment contributing DA\n",
    "origDA = np.full((len(resnet.ShortID), numt), np.nan) #original drainage area through time\n",
    "\n",
    "for j in range(len(resnet.ShortID)):\n",
    "    origDA[j,:] = resnet.iloc[j].DivDASqKM\n",
    "\n",
    "wSAatdam = np.full((len(resnet.ShortID), 1), np.nan) #Time-weighted sediment-contributing drainage area above reservoir X\n",
    "AveTrap = np.full((len(resnet.ShortID), 1), np.nan) #time-weighted trap efficiency\n",
    "wseddel = np.full((len(resnet.ShortID), 1), np.nan) #m3, total volume of sediment delivered to reservoir X between time 1 and time 2\n",
    "wSDR = np.full((len(resnet.ShortID), 1), np.nan) #m3/yr, sediment delivery rate, mean volume of sediment delivered to reservoir X per year between time 1 and time 2\n",
    "wSDRyield = np.full((len(resnet.ShortID), 1), np.nan) #m3/(km3*t), sediment yield, volume of sediment per km2 per year\n",
    "\n",
    "sedDAtoDS = np.full((len(resnet.ShortID), numt), np.nan) #drainage area that moves downstream\n",
    "SAatdam = origDA #sediment contributing drainage area upstream from reservoir X (does not include trap efficiency at reservoir X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "93ecc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trap efficiency\n",
    "\n",
    "#for kappa: coarse (sand) = 1, medium (silt) = 0.1, fine (clay) = 0.046\n",
    "#we use the design assumption for reservoirs of silt\n",
    "kappa = np.full((len(resnet.ShortID), 1), 0.1)\n",
    "\n",
    "#setting initial trap efficiency. Before and after the dam is in place it is zero. While the dam exists, calculate a value.\n",
    "#This trap efficiency is static through time based on the initial TE.\n",
    "for j in range(len(resnet.ShortID)):\n",
    "    #assign trap efficiency as 0 before dam completion\n",
    "    yrc = resnet.iloc[j].yrc\n",
    "    yrr = resnet.iloc[j].yrr\n",
    "    \n",
    "    \n",
    "    # Assuming 't' is a NumPy array and 'data' is a pandas DataFrame\n",
    "    predam = np.where(t < yrc)[0]\n",
    "\n",
    "    # Handling cases where yrr might be NaN\n",
    "    if np.isnan(yrr):\n",
    "        postdam = np.where(t >= yrc)[0]\n",
    "        removed = np.array([])  # No dams removed\n",
    "    else:\n",
    "        postdam = np.where((t >= yrc) & (t < yrr))[0]\n",
    "        removed = np.where(t >= yrr)[0]\n",
    "\n",
    "        calctrap[j, removed] = 0\n",
    "        capcalc[j, removed] = 0\n",
    "\n",
    "    # Initialize arrays (assuming calctrap and capcalc exist)\n",
    "    calctrap[j, predam] = 0\n",
    "    capcalc[j, predam] = 0\n",
    "\n",
    "    origDA[j, :] = resnet.iloc[j].DivDASqKM\n",
    "\n",
    "    calctrap[j, postdam] = 1 - 1. / (1 + kappa[j] * ((resnet.iloc[j].MaxStor_m3 / convert1) / (resnet.iloc[j].DivDASqKM / convert2)))\n",
    "\n",
    "    capcalc[j, postdam] = resnet.iloc[j].MaxStor_m3\n",
    "\n",
    "    # Since static, take the first trap efficiency for AveTrap\n",
    "    AveTrap[j, 0] = calctrap[j, postdam[0]]      \n",
    " \n",
    "\n",
    "for i in range(int(max(resnet.Rank))):\n",
    "    ranknum = np.where(resnet.Rank == i)[0]\n",
    "    jmax = len(ranknum)\n",
    "    sedshed[ranknum,:] = SAatdam[ranknum,:] * calctrap[ranknum,:] #km2, this will calculate sedshed for the rank we are on\n",
    "    sedDAtoDS[ranknum,:] = SAatdam[ranknum,:] - sedshed[ranknum,:] #km2, this is the volume moving downstream past the dam in a given year\n",
    "\n",
    "    for j in range(jmax):\n",
    "        val = ranknum[j]\n",
    "        if resnet.iloc[val].flagTerm == 0: #If it isn't a terminal dam, move the drainage area downstream\n",
    "            todam = np.where(resnet.ShortID == resnet.iloc[val].ToDam)\n",
    "            SAatdam[todam,:] = SAatdam[todam,:] - (resnet.iloc[val].DivDASqKM - sedDAtoDS[val,:]) #Adjusts SA at dam for next time loop. Rank of this dam must be higher than dam it comes from\n",
    "                \n",
    "            #double check for any drainage area errors that can be caused by flow diversions\n",
    "            DAerror = np.where(SAatdam[todam,:]<0)[0]\n",
    "            if len(DAerror)>0:\n",
    "                print('Drainage area error! Upstream drainage area is larger than downstream drainage area.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a5438cc-4c41-47c4-9e6c-b39142b1c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert output to a dataframe\n",
    "df = pd.DataFrame(SAatdam, columns=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ab45d4b-f1f4-4500-8b31-af2fd8f56933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rejoin to the original dataset to add rivers back in and remove Canadian dams used in SCA routing.\n",
    "\n",
    "#SA at dam\n",
    "resnet['SCA2025'] = df[2025]\n",
    "# join back to original so keeps original ToDam. Adds field for Rank and SCA 2025. Transfer over flagTerm\n",
    "\n",
    "resnet_orig = resnet_orig.drop('flagTerm',axis=1)\n",
    "\n",
    "final = pd.merge(resnet_orig,resnet[['ShortID','flagTerm','Rank','SCA2025']],on='ShortID',how='left')\n",
    "\n",
    "#save file\n",
    "final.to_csv(f'Outputs/ResNet_SCA_{today}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48d242-881a-435b-9ccd-e19bdd43803f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:resnet]",
   "language": "python",
   "name": "conda-env-resnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
