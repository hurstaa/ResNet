{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00da325",
   "metadata": {},
   "source": [
    "This notebook calculates the sediment contributing drainage area in the year 2025 for all of ResNet using the methods of Minear and Kondolf (xxxx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367ecd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a1eeb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "# ResNet File location and name\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "# resnet_orig = pd.read_csv(f'Outputs/ResNet_{today}.csv')\n",
    "resnet_orig = pd.read_csv(f'Outputs/ResNet_20250507.csv')\n",
    "\n",
    "#load canadian dams for calculating\n",
    "canada = pd.read_csv('Inputs/InputCanada.csv')\n",
    "\n",
    "#output file location\n",
    "out_folder = 'Outputs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a291a57b-b927-4c6d-bce1-b73acdd83019",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_orig['yrr'] = resnet_orig['yrr'].replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f5ecf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversions\n",
    "convert1 = 1233.482 #converts m3 to ac-ft is convert1*AF=m3, or from m3 is m3/convert1=AF\n",
    "convert2 = 2.59 #converts km2 and mi2 is convert2*mi2=km2 or from km2 is km2/convert2=mi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d3cfa581-3cae-43ec-b028-d7faba2f14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert strings to lists\n",
    "# canada['FromDam'] = canada['FromDam'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)\n",
    "# canada['ToDam'] = canada['ToDam'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)\n",
    "# canada['flag'] = canada['flag'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "30b9c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine Canada and resnet\n",
    "resnet = pd.concat([resnet_orig,canada],ignore_index=True)\n",
    "\n",
    "resnet = resnet.sort_values(by='ShortID',ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "50866ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually add major Canadian dams to the routing in the Columbia River basin for calculating sediment contributing drainage area\n",
    "\n",
    "## Boundary Dam\n",
    "resnet.loc[resnet.ShortID==117361, 'ToDam'] = 500005 #route to a Canadian dam, not directly to Grand Coulee\n",
    "resnet.loc[resnet.ShortID==117361, 'GRanDTag'] = 500005\n",
    "\n",
    "## Libby Dam\n",
    "resnet.loc[resnet.ShortID==78196, 'ToDam'] = 500003 #route to a Canadian dam, not directly to Grand Coulee\n",
    "resnet.loc[resnet.ShortID==78196, 'GRanDTag'] = 500003\n",
    "\n",
    "## Grand Coulee Dam\n",
    "resnet.loc[resnet.ShortID==117548, 'FromDam'] = resnet.loc[resnet.ShortID==117548, 'FromDam'].apply(\n",
    "lambda x: [num for num in x if num not in {117361,78196}]) #remove Libby and Boundary ShortIDs from Coulee FromDam\n",
    "\n",
    "resnet.loc[resnet.ShortID==117548, 'FromDam'] = resnet.loc[resnet.ShortID==117548, 'FromDam'].apply(\n",
    "lambda x: x + [500002, 500004, 500006]) #Add Canadian dams to Coulee FromDam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2c89bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think this entire cell can likely be deleted.\n",
    "\n",
    "#changes yrr from 0/nan to 3001, ignore.\n",
    "\n",
    "#changes nan todam to 0. again, can probably ignore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d6b2074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rivers from ToDam so only dams are routed to dams.\n",
    "\n",
    "damstoriver = resnet.loc[resnet.ToDam<0]\n",
    "\n",
    "while len(damstoriver)>0:\n",
    "    for i in range(len(damstoriver)):\n",
    "        #find a dam that goes to a river instead of another dam\n",
    "        damlocationtofix = damstoriver.index[i] #index of the dam to fix\n",
    "        river = resnet.loc[damlocationtofix,'ToDam'] #ShortID of the river it goes to\n",
    "        riverloc = resnet.loc[resnet.ShortID==river].index #location of the river\n",
    "        rivertodam = resnet.loc[riverloc,'ToDam'] #the ToDam of the river\n",
    "        resnet.loc[damlocationtofix,'ToDam'] = rivertodam.iloc[0] #replace ToDam of target dam with ToDam of river\n",
    "    damstoriver = resnet.loc[resnet.ToDam<0]\n",
    "    \n",
    "#Test this without loop version:\n",
    "# # Identify dams that route to rivers\n",
    "# damstoriver = resnet[resnet.ToDam < 0]\n",
    "\n",
    "# # Create a mapping from rivers to their corresponding ToDam values\n",
    "# river_to_dam_map = resnet.set_index(\"ShortID\")[\"ToDam\"]\n",
    "\n",
    "# # Replace ToDam values of dams that currently route to rivers\n",
    "# resnet.loc[damstoriver.index, \"ToDam\"] = damstoriver[\"ToDam\"].map(river_to_dam_map).fillna(damstoriver[\"ToDam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7515a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now that to dam has been replaced on real dams, remove to dam from rivers\n",
    "resnet.loc[resnet.IsRiverMth==1,'ToDam'] = np.nan\n",
    "\n",
    "#fix terminal dam flag after removing rivers\n",
    "resnet.loc[resnet.ToDam.isna(),'flagTerm'] = 1\n",
    "resnet.loc[resnet.IsRiverMth==1, 'flagTerm'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "89fe6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking dams and assigning dam order (similar to stream order). This does not include Rivers.\n",
    "\n",
    "Rank = np.full(len(resnet['ShortID']),np.nan)\n",
    "Rank[np.where(resnet.flagHW==1)[0]] = 1\n",
    "Rank[np.where(resnet.IsRiverMth == 1)[0]] = 0\n",
    "\n",
    "        # damloc = np.where(dam.Hydroseq == d_s)[0][0] # Find which dam we reached\n",
    "        \n",
    "        # ToDam[i] = dam.ShortID[damloc] # Update the ToDam column\n",
    "\n",
    "Dam1 = []\n",
    "Dam2 = []\n",
    "DA1 = []\n",
    "DA2 = []\n",
    "\n",
    "DAerrorNumber = 0;\n",
    "ranknum= np.where(Rank == 1)[0]\n",
    "while len(ranknum)>0:\n",
    "    for j in range(len(ranknum)):\n",
    "        thisdam = ranknum[j]\n",
    "\n",
    "        # if resnet.ShortID[thisdam] < 0: #deal with river drainage areas\n",
    "        #     toriv = np.where(resnet.ToDam == resnet.ShortID[thisdam])[0]\n",
    "        #     totDAtoriv = resnet.DivDASqKM[toriv].sum()\n",
    "        #     if totDAtoriv > resnet.DivDASqKM[thisdam]:\n",
    "        #         resnet.DivDASqKM[thisdam] = totDAtoriv\n",
    "\n",
    "        #process nonterminal dams\n",
    "        if resnet.iloc[thisdam].flagTerm == 0: #if the dam is not a terminal dam\n",
    "            thisdamDA = resnet.iloc[thisdam].DivDASqKM #identify the drainage area of dam j\n",
    "            thatdam = np.where(resnet.ShortID == resnet.iloc[thisdam].ToDam)[0][0] #find the downstream dam\n",
    "            thatdamDA = resnet.iloc[thatdam].DivDASqKM #get the drainage area of the downstream dam\n",
    "\n",
    "            #make sure the downstream DA doesn't exceed the upstream DA\n",
    "            if (thatdamDA<thisdamDA):\n",
    "                DAerrorNumber = DAerrorNumber+1\n",
    "                Dam1.append(resnet.iloc[thisdam].ShortID)\n",
    "                Dam2.append(resnet.iloc[thatdam].ShortID)\n",
    "                DA1.append(thisdamDA)\n",
    "                DA2.append(thatdamDA)\n",
    "                \n",
    "            else:\n",
    "                Rank[thatdam] = Rank[thisdam]+1\n",
    "    i = i+1\n",
    "    ranknum = np.where(Rank == i)[0]\n",
    "\n",
    "if DAerrorNumber != 0:\n",
    "    print(\"Drainage area error: manually investigate drainage areas in GIS\")\n",
    "\n",
    "resnet['Rank']=Rank\n",
    "\n",
    "DAerrors = pd.DataFrame({'Dam1': Dam1, 'Dam2': Dam2, 'DA1': DA1, 'DA2': DA2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "65e3472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of rivers\n",
    "resnet = resnet.loc[resnet['IsRiverMth'] != 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "709742c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For unreasonable or nonexistent yrc, replace with the 90th percentile of when dams were built; earlier than 1700 or later than 2024\n",
    "\n",
    "# Identify valid values (1700 ≤ yrc ≤ 2024)\n",
    "valid_yrc = resnet.loc[(resnet['yrc'] >= 1700) & (resnet['yrc'] <= 2024), 'yrc']\n",
    "\n",
    "# Compute the 90th percentile from valid values\n",
    "percentile_90 = np.percentile(valid_yrc, 90)\n",
    "\n",
    "# Replace out-of-range values with the 90th percentile\n",
    "resnet.loc[(resnet['yrc'] < 1700) | (resnet['yrc'] > 2024), \"yrc\"] = percentile_90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b865e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the timeseries\n",
    "t = np.arange(1699, 2051) #should this start in 1699 or 1700? check back in matlab code melissa shared\n",
    "numdam=len(resnet.ShortID); #number of dams\n",
    "numt=len(t); #length of time\n",
    "\n",
    "#create empty variables\n",
    "capcalc = np.full((len(resnet.ShortID), numt), np.nan) #this is a variable that would need to be stored in the structure\n",
    "sedshed = np.full((len(resnet.ShortID), numt), np.nan) #this is the km2 area of the watershed that has sediment getting trapped in reservoir (so contribut DA * trap efficiency)\n",
    "calctrap = np.full((len(resnet.ShortID),numt),0)\n",
    "wsedshed = np.full((len(resnet.ShortID), 1), np.nan) #effective sediment contributing DA\n",
    "origDA = np.full((len(resnet.ShortID), numt), np.nan) #original drainage area through time\n",
    "\n",
    "for j in range(len(resnet.ShortID)):\n",
    "    origDA[j,:] = resnet.iloc[j].DivDASqKM\n",
    "\n",
    "wSAatdam = np.full((len(resnet.ShortID), 1), np.nan) #Time-weighted sediment-contributing drainage area above reservoir X\n",
    "AveTrap = np.full((len(resnet.ShortID), 1), np.nan) #time-weighted trap efficiency\n",
    "wseddel = np.full((len(resnet.ShortID), 1), np.nan) #m3, total volume of sediment delivered to reservoir X between time 1 and time 2\n",
    "wSDR = np.full((len(resnet.ShortID), 1), np.nan) #m3/yr, sediment delivery rate, mean volume of sediment delivered to reservoir X per year between time 1 and time 2\n",
    "wSDRyield = np.full((len(resnet.ShortID), 1), np.nan) #m3/(km3*t), sediment yield, volume of sediment per km2 per year\n",
    "\n",
    "sedDAtoDS = np.full((len(resnet.ShortID), numt), np.nan) #drainage area that moves downstream\n",
    "SAatdam = origDA #sediment contributing drainage area upstream from reservoir X (does not include trap efficiency at reservoir X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4a6567af-6ac8-4dd2-a55a-ea322515781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works to here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "93ecc9d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'isnan'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[360]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m predam = np.where(t < yrc)[\u001b[32m0\u001b[39m]\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Handling cases where yrr might be NaN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m yrr.isnan():\n\u001b[32m     20\u001b[39m     postdam = np.where(t >= yrc)[\u001b[32m0\u001b[39m]\n\u001b[32m     21\u001b[39m     removed = np.array([])  \u001b[38;5;66;03m# No dams removed\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.float64' object has no attribute 'isnan'"
     ]
    }
   ],
   "source": [
    "# Trap efficiency\n",
    "\n",
    "#for kappa: coarse (sand) = 1, medium (silt) = 0.1, fine (clay) = 0.046\n",
    "#we use the design assumption for reservoirs of silt\n",
    "kappa = np.full((len(resnet.ShortID), 1), 0.1)\n",
    "\n",
    "#setting initial trap efficiency. Before and after the dam is in place it is zero. While the dam exists, calculate a value.\n",
    "#This trap efficiency is static through time based on the initial TE.\n",
    "for j in range(len(resnet.ShortID)):\n",
    "    #assign trap efficiency as 0 before dam completion\n",
    "    yrc = resnet.iloc[j].yrc\n",
    "    yrr = resnet.iloc[j].yrr\n",
    "    \n",
    "    \n",
    "    # Assuming 't' is a NumPy array and 'data' is a pandas DataFrame\n",
    "    predam = np.where(t < yrc)[0]\n",
    "\n",
    "    # Handling cases where yrr might be NaN\n",
    "    if yrr.isnan():\n",
    "        postdam = np.where(t >= yrc)[0]\n",
    "        removed = np.array([])  # No dams removed\n",
    "    else:\n",
    "        postdam = np.where((t >= yrc) & (t < yrr))[0]\n",
    "        removed = np.where(t >= yrr)[0]\n",
    "\n",
    "        calctrap[j, removed] = 0\n",
    "        capcalc[j, removed] = 0\n",
    "\n",
    "    # Initialize arrays (assuming calctrap and capcalc exist)\n",
    "    calctrap[j, predam] = 0\n",
    "    capcalc[j, predam] = 0\n",
    "\n",
    "    origDA[j, :] = resnet.iloc[j].DivDASqKM\n",
    "\n",
    "    calctrap[j, postdam] = 1 - 1. / (1 + kappa[j] * ((resnet.iloc[j].MaxStor_m3 / convert1) / (resnet.iloc[j].DivDASqKM / convert2)))\n",
    "\n",
    "    capcalc[j, postdam] = resnet.iloc[j].MaxStor_m3\n",
    "\n",
    "    # Since static, take the first trap efficiency for AveTrap\n",
    "    AveTrap[j, 0] = calctrap[j, postdam[0]]\n",
    "    \n",
    " \n",
    "\n",
    "for i in range(max(resnet.Rank)):\n",
    "    ranknum = np.where(resnet.Rank == i)[0]\n",
    "    jmax = len(ranknum)\n",
    "    sedshed[ranknum,:] = SAatdam[ranknum,:] * calctrap[ranknum,:] #km2, this will calculate sedshed for the rank we are on\n",
    "    sedDAtoDS[ranknum,:] = SAatdam[ranknum,:] - sedshed[ranknum,:] #km2, this is the volume moving downstream past the dam in a given year\n",
    "        \n",
    "    for j in range(jmax):\n",
    "        val = ranknum[j]\n",
    "        if resnet.iloc[val].flagTerm == 0: #If it isn't a terminal dam, move the drainage area downstream\n",
    "            todam = np.where(resnet.ShortID == resnet.iloc[val].ToDam)\n",
    "            SAatdam[todam,:] = SAatdam[todam,:] - (resnet.iloc[val].DivDASqKM - sedDAtoDS[val,:]) #Adjusts SA at dam for next time loop. Rank of this dam must be higher than dam it comes from\n",
    "                \n",
    "            #double check for any drainage area errors that can be caused by flow diversions\n",
    "            DAerror = np.where(SAatdam[todam,:]<0)[0]\n",
    "            if len(DAerror)>0:\n",
    "                print('Drainage area error! Upstream drainage area is larger than downstream drainage area.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691ca2d-3308-47af-99aa-3ed0c63525e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4afbc-8b3a-40c7-aa7d-b5623df2c743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad401281-e625-4487-a132-9a4aae70d019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fill in year prediction & capp- abby loop uses capp, so leave for now- this uses CAPP.  not sure what aaron needs.  may need to just set capp = capc or change code to have capc\n",
    "# %sometimes a survey shows a growth in capacity- dam raise, or better survey technique etc. We have these data for some\n",
    "# %Usace and usbr sites. here, the prediction year (yrp) is the newer survey.  Alternatively, sometimes there was no original survey\n",
    "# % and the first survey was collected later. We will back calculate between yrp and yrc. \n",
    "# %if no yrp, then yrp=yrc\n",
    "# % cap p is capacity at year p\n",
    "\n",
    "#yrp is just yrc\n",
    "\n",
    "#Just use MaxStor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0ab45d4b-f1f4-4500-8b31-af2fd8f56933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop canadian dams and put todam and fromdam back to original from running resnet?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aece63",
   "metadata": {},
   "source": [
    "# All matlab below here for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637190fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Save MLR TimesSeries Input...... you would want to change this file name for your export\n",
    "%timeseries output, for MLR input\n",
    "MLR_SAatdam_timeseries=NaN((numdam+1),(numt+1));\n",
    "MLR_SAatdam_timeseries(1,2:end)=t;\n",
    "MLR_SAatdam_timeseries(2:end,1)=data.SID;\n",
    "MLR_SAatdam_timeseries(2:end,2:end)=SAatdam_TEyrc(:,:);\n",
    "writematrix(MLR_SAatdam_timeseries,MLRfilename2,'Delimiter',',');\n",
    "\n",
    "\n",
    "save MLRdata.mat\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:resnet]",
   "language": "python",
   "name": "conda-env-resnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
